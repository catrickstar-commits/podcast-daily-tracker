import requests
import pandas as pd
from datetime import datetime
import os
import time
from playwright.sync_api import sync_playwright

# === æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨å¤šä¸ªé•œåƒæºè½®è¯¢ ===
# å¦‚æœç¬¬ä¸€ä¸ªæŒ‚äº†ï¼Œè‡ªåŠ¨å°è¯•ç¬¬äºŒä¸ª
RSSHUB_DOMAINS = [
    "https://rsshub.app",                 # å®˜æ–¹èŠ‚ç‚¹ï¼ˆå®¹æ˜“è¢«å¢™ï¼‰
    "https://rsshub.rssforever.com",      # å¤‡ç”¨èŠ‚ç‚¹1
    "https://rsshub.ktachibana.party",    # å¤‡ç”¨èŠ‚ç‚¹2
    "https://rss.fatpandac.com"           # å¤‡ç”¨èŠ‚ç‚¹3
]

ROUTES = {
    "ç¼–è¾‘æ¨è": "/xiaoyuzhou/editor_choice",
    "çƒ­é—¨æ¦œ": "/xiaoyuzhou/ranking/hot",
    "é”‹èŠ’æ¦œ": "/xiaoyuzhou/ranking/sharp",
    "æ–°æ˜Ÿæ¦œ": "/xiaoyuzhou/ranking/new"
}

def get_today_date():
    return datetime.now().strftime("%Y-%m-%d")

# å°è¯•ä»ä¸åŒçš„æºè·å–æ•°æ®
def fetch_data_with_retry(route):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    
    for domain in RSSHUB_DOMAINS:
        url = f"{domain}{route}.json"
        print(f"æ­£åœ¨å°è¯•æ¥å£: {url} ...")
        try:
            resp = requests.get(url, headers=headers, timeout=10)
            if resp.status_code == 200:
                print("âœ… è·å–æˆåŠŸï¼")
                return resp.json()
            else:
                print(f"âŒ å¤±è´¥ (çŠ¶æ€ç : {resp.status_code})")
        except Exception as e:
            print(f"âŒ è¿æ¥è¶…æ—¶æˆ–é”™è¯¯: {e}")
            
    print("âš ï¸ æ‰€æœ‰çº¿è·¯éƒ½å¤±è´¥äº†")
    return None

def fetch_all_data():
    all_data = []
    print("ğŸš€ å¼€å§‹å¤šçº¿è·¯æŠ“å–æ•°æ®...")
    
    for category, route in ROUTES.items():
        data = fetch_data_with_retry(route)
        
        if data:
            items = data.get('items', [])
            for index, item in enumerate(items[:10]): 
                all_data.append({
                    "æ—¥æœŸ": get_today_date(),
                    "æ¦œå•ç±»å‹": category,
                    "æ’å": index + 1,
                    "æ’­å®¢æ ‡é¢˜": item.get('title', 'æ— æ ‡é¢˜'),
                    "ä½œè€…": item.get('author', {}).get('name', 'æœªçŸ¥'),
                    "é“¾æ¥": item.get('url', '')
                })
        else:
            print(f"âš ï¸ è­¦å‘Šï¼šæ— æ³•è·å– [{category}] çš„æ•°æ®")

    return pd.DataFrame(all_data)

def save_csv(df):
    filename = "xiaoyuzhou_data.csv"
    if os.path.exists(filename):
        df.to_csv(filename, mode='a', header=False, index=False, encoding='utf-8-sig')
    else:
        df.to_csv(filename, index=False, encoding='utf-8-sig')
    print("ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° CSV")

def generate_chart_screenshot(df):
    if df.empty: return
    print("ğŸ¨ æ­£åœ¨ç”Ÿæˆæ¦œå•é•¿å›¾...")
    
    html = f"""
    <html>
    <head>
        <meta charset="utf-8">
        <style>
            body {{ font-family: sans-serif; background: #f6f6f6; padding: 20px; width: 400px; }}
            .header {{ text-align: center; margin-bottom: 20px; }}
            .title {{ font-size: 24px; font-weight: bold; color: #333; }}
            .date {{ color: #888; font-size: 14px; margin-top: 5px; }}
            .card {{ background: white; border-radius: 12px; padding: 15px; margin-bottom: 20px; box-shadow: 0 2px 8px rgba(0,0,0,0.05); }}
            .card-title {{ font-size: 18px; font-weight: bold; margin-bottom: 10px; border-left: 4px solid #ff5e5e; padding-left: 10px; }}
            .row {{ display: flex; align-items: center; margin-bottom: 12px; border-bottom: 1px solid #eee; padding-bottom: 8px; }}
            .rank {{ font-size: 18px; font-weight: bold; color: #ff5e5e; width: 30px; }}
            .info {{ flex: 1; overflow: hidden; }}
            .p-title {{ font-size: 15px; font-weight: 500; color: #333; margin: 0 0 4px 0; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; }}
            .p-author {{ font-size: 12px; color: #999; margin: 0; }}
        </style>
    </head>
    <body>
        <div class="header">
            <div class="title">å°å®‡å®™æ—¥æŠ¥</div>
            <div class="date">{get_today_date()}</div>
        </div>
    """
    
    for category in ROUTES.keys():
        subset = df[df['æ¦œå•ç±»å‹'] == category]
        if subset.empty: continue
        
        html += f'<div class="card"><div class="card-title">{category} Top 10</div>'
        for _, row in subset.iterrows():
            html += f"""
            <div class="row">
                <div class="rank">{row['æ’å']}</div>
                <div class="info">
                    <p class="p-title">{row['æ’­å®¢æ ‡é¢˜']}</p>
                    <p class="p-author">{row['ä½œè€…']}</p>
                </div>
            </div>
            """
        html += '</div></body></html>'
    
    with open("temp_chart.html", "w", encoding="utf-8") as f:
        f.write(html)
        
    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(f"file://{os.getcwd()}/temp_chart.html")
        page.screenshot(path=f"daily_chart_{get_today_date()}.png", full_page=True)
        browser.close()
        print("ğŸ“¸ æ¦œå•æˆªå›¾å®Œæˆ")

def capture_homepage():
    print("ğŸ“¸ æ­£åœ¨æˆªå–å®˜ç½‘é¦–é¡µ...")
    with sync_playwright() as p:
        iphone = p.devices['iPhone 12']
        browser = p.chromium.launch()
        context = browser.new_context(**iphone)
        page = context.new_page()
        try:
            page.goto("https://www.xiaoyuzhoufm.com/", timeout=60000)
            page.wait_for_timeout(5000)
            page.screenshot(path=f"homepage_{get_today_date()}.png")
            print("âœ… é¦–é¡µæˆªå›¾å®Œæˆ")
        except Exception as e:
            print(f"âŒ é¦–é¡µæˆªå›¾å¤±è´¥: {e}")
        finally:
            browser.close()

if __name__ == "__main__":
    df = fetch_all_data()
    
    if not df.empty:
        save_csv(df)
        generate_chart_screenshot(df)
        capture_homepage()
    else:
        # å¼ºåˆ¶æŠ¥é”™ï¼Œè®© GitHub Action å˜çº¢ï¼Œæç¤ºç”¨æˆ·å‡ºé”™äº†
        raise Exception("âŒ æ‰€æœ‰çº¿è·¯å‡æ— æ³•è·å–æ•°æ®ï¼Œè¯·æ£€æŸ¥ RSSHub çŠ¶æ€ï¼")
